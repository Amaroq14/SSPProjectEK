{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparative evaluation of surgical methods in the treatment of chronic irreparable supraspinatus tears: a biomechanical study\n",
        "\n",
        "### **Authors**\n",
        "\n",
        "**E. Koumantou**$^{a,*}$, **C. J. Feroussis**$^{b}$, **E. D. Pasiou**$^{a}$, **S. K. Kourkoulis**$^{a}$\n",
        "\n",
        "### **Affiliations**\n",
        "\n",
        "> **a** National Technical University of Athens, School of Applied Mathematical and Physical Sciences, Department of Mechanics, Laboratory of Biomechanics and Biomedical Physics, Iroon Polytechniou 5, 15773 Zografou, Greece\n",
        ">\n",
        "> **b** National and Kapodistrian University of Athens, School of Medicine, Mikras Asias 75, Athens, Greece\n",
        "\n",
        "---\n",
        "\n",
        "## **Abstract**\n",
        "\n",
        "Chronic irreparable supraspinatus (SSP) tears are frequently treated using tensor fascia lata (TFL); however, these grafts are prone to recurrent ruptures. A TFL scaffold with seeded mesenchymal stem cells (MSCs) may increase the mechanical strength of the regenerated tendon. In this experimental study the above hypothesis is evaluated and the healing qualities of the MSC embedded scaffold are compared against the ones repaired with only a TFL allograft, from a biomechanical perspective. A number of skeletally mature male rabbits were used to create a chronic retracted SSP tear model. A tendon defect was created at the right shoulder of each specimen and was reconstructed six weeks later using a TFL allograft either with or without MSCs embedded. The rabbits were sacrificed twelve weeks after the operation and their biomechanical evaluation was based on the tendon's ultimate failure load and stiffness of each group. The results of the biomechanical analysis revealed that the MSC group demonstrated a higher tensile strength than the TFL group. The values of the mean ultimate failure load and the mean stiffness of both TFL and MSC groups were significantly lower compared to the respective values obtained for the intact rotator cuff (RC) group. It seems that bone marrow MSCs increased the mechanical strength of the supraspinatus tendon; however, the stiffness was similar between the operated groups in rabbit models. Based on the results, it could be stated that rotator cuff regeneration using MSCs appears as a promising approach; nonetheless, additional clinical evidence is required, before definite conclusions are drawn.\n",
        "\n",
        "---"
      ],
      "id": "5284e694"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Setup, Configuration & Core Functions\n",
        "\n",
        "This is a **self-contained** notebook. All configuration and analysis functions are defined inline.\n",
        "\n",
        "**Configuration:**\n",
        "- Group assignments (TFL / MSC) are hardcoded below\n",
        "- Data is read from `Selected_data/` (relative to this notebook)\n",
        "- Results are saved to `Results/`\n",
        "\n",
        "**Analysis pipeline:**\n",
        "- Filename parsing and sample classification\n",
        "- Data validation and normalization\n",
        "- Stiffness calculation via sliding-window linear regression\n",
        "- Energy (area under curve) via trapezoidal rule\n",
        "- Group statistics and visualizations"
      ],
      "id": "e2923393"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Uncomment to install dependencies if needed\n",
        "# %pip install plotly pandas numpy matplotlib scikit-learn"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1512b4ee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION (hardcoded — no external config.json needed)\n",
        "# ============================================================================\n",
        "\n",
        "NOTEBOOK_DIR = Path('.').resolve()\n",
        "DATA_FOLDER = NOTEBOOK_DIR / 'Selected_data'\n",
        "RESULTS_FOLDER = NOTEBOOK_DIR / 'Results'\n",
        "RESULTS_FOLDER.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Treatment group assignments\n",
        "TFL_IDS = ['B1', 'B10', 'B11', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8']\n",
        "MSC_IDS = ['B5', 'B6', 'B7', 'B9', 'C1', 'C2', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15']\n",
        "\n",
        "# Analysis parameters\n",
        "STIFFNESS_R2_THRESHOLD = 0.99\n",
        "STIFFNESS_WINDOW_FRACTION = 0.1\n",
        "STIFFNESS_MIN_WINDOW = 5\n",
        "\n",
        "# ============================================================================\n",
        "# SAMPLE SELECTION\n",
        "# ============================================================================\n",
        "# All available sample IDs (for reference):\n",
        "#   B-series:  B1, B5, B6, B7, B9, B10, B11\n",
        "#   C-series:  C1, C2\n",
        "#   D-series:  D1, D2, D3, D4, D5, D6, D7, D8, D9, D10, D11, D12, D13, D14, D15\n",
        "#\n",
        "# To EXCLUDE specific samples, add their IDs to the list below.\n",
        "# Example: EXCLUDED_SAMPLES = ['B1', 'D15', 'C2']\n",
        "# To include all samples, leave the list empty: EXCLUDED_SAMPLES = []\n",
        "\n",
        "EXCLUDED_SAMPLES: list = []\n",
        "\n",
        "# Derive the active sample lists (automatically filters out excluded samples)\n",
        "ACTIVE_TFL = [s for s in TFL_IDS if s not in EXCLUDED_SAMPLES]\n",
        "ACTIVE_MSC = [s for s in MSC_IDS if s not in EXCLUDED_SAMPLES]\n",
        "\n",
        "if EXCLUDED_SAMPLES:\n",
        "    print(f\"⚠ Excluded samples: {EXCLUDED_SAMPLES}\")\n",
        "    print(f\"  Active TFL IDs ({len(ACTIVE_TFL)}): {ACTIVE_TFL}\")\n",
        "    print(f\"  Active MSC IDs ({len(ACTIVE_MSC)}): {ACTIVE_MSC}\")\n",
        "else:\n",
        "    print(\"All samples included (no exclusions).\")\n",
        "\n",
        "# Optional: Interactive plotting with Plotly\n",
        "PLOTLY_AVAILABLE = False\n",
        "try:\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "    import plotly.express as px\n",
        "    PLOTLY_AVAILABLE = True\n",
        "    print(\"Plotly loaded - interactive plots enabled!\")\n",
        "except ImportError:\n",
        "    print(\"Plotly not available. Install with: pip install plotly\")\n",
        "    print(\"Falling back to matplotlib (non-interactive) plots.\")\n",
        "\n",
        "# Set plot style\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "except OSError:\n",
        "    try:\n",
        "        plt.style.use('seaborn-whitegrid')\n",
        "    except OSError:\n",
        "        pass  # Use default style\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "\n",
        "print(f\"Data folder: {DATA_FOLDER}\")\n",
        "print(f\"Results folder: {RESULTS_FOLDER}\")\n",
        "print(f\"\\nActive TFL IDs ({len(ACTIVE_TFL)}): {ACTIVE_TFL}\")\n",
        "print(f\"Active MSC IDs ({len(ACTIVE_MSC)}): {ACTIVE_MSC}\")\n",
        "print(f\"Total active samples: {len(ACTIVE_TFL) + len(ACTIVE_MSC)}\")\n",
        "print(f\"\\nAnalysis parameters:\")\n",
        "print(f\"  R² threshold: {STIFFNESS_R2_THRESHOLD}\")\n",
        "print(f\"  Window fraction: {STIFFNESS_WINDOW_FRACTION}\")\n",
        "print(f\"  Min window: {STIFFNESS_MIN_WINDOW}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FILENAME PARSING & CLASSIFICATION (from utils.py)\n",
        "# ============================================================================\n",
        "\n",
        "def parse_filename(filename: str) -> Tuple[Optional[str], str]:\n",
        "    \"\"\"\n",
        "    Parse an SSP data filename to extract subject ID and condition.\n",
        "    Returns (subject_id, condition).\n",
        "    \"\"\"\n",
        "    condition = 'Unknown'\n",
        "    if '_NO' in filename or '_NO.' in filename:\n",
        "        condition = 'NO'\n",
        "    elif '_OPER' in filename:\n",
        "        condition = 'OPER'\n",
        "\n",
        "    subject_id = None\n",
        "    parts = filename.replace('.csv', '').split('_')\n",
        "    for part in parts:\n",
        "        if re.match(r'^[BCD]\\d{1,2}$', part):\n",
        "            subject_id = part\n",
        "            break\n",
        "\n",
        "    return subject_id, condition\n",
        "\n",
        "\n",
        "def classify_sample(\n",
        "    filename: str,\n",
        "    tfl_ids: List[str],\n",
        "    msc_ids: List[str]\n",
        ") -> Tuple[str, str, str]:\n",
        "    \"\"\"\n",
        "    Parse filename to find Sample ID, Condition (NO/OPER), and Subgroup.\n",
        "    Returns (sample_id, condition, subgroup).\n",
        "    \"\"\"\n",
        "    subject_id, condition = parse_filename(filename)\n",
        "\n",
        "    if subject_id is None:\n",
        "        subject_id = 'Unknown'\n",
        "\n",
        "    subgroup = 'Unassigned'\n",
        "    if condition == 'NO':\n",
        "        subgroup = 'NON'\n",
        "    elif condition == 'OPER':\n",
        "        if subject_id in tfl_ids:\n",
        "            subgroup = 'TFL'\n",
        "        elif subject_id in msc_ids:\n",
        "            subgroup = 'MSC'\n",
        "\n",
        "    return subject_id, condition, subgroup\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA VALIDATION & NORMALIZATION (from utils.py)\n",
        "# ============================================================================\n",
        "\n",
        "def validate_raw_data(df: pd.DataFrame) -> List[str]:\n",
        "    \"\"\"Validate that a raw data DataFrame has required columns and valid values.\"\"\"\n",
        "    errors = []\n",
        "    required_cols = ['Crossheadmm', 'LoadN']\n",
        "    for col in required_cols:\n",
        "        if col not in df.columns:\n",
        "            if col == 'LoadN' and 'LoadkN' in df.columns:\n",
        "                continue\n",
        "            errors.append(f'Missing required column: {col}')\n",
        "\n",
        "    if errors:\n",
        "        return errors\n",
        "\n",
        "    if len(df) == 0:\n",
        "        errors.append('Data file is empty')\n",
        "        return errors\n",
        "\n",
        "    if 'Crossheadmm' in df.columns:\n",
        "        if df['Crossheadmm'].isna().all():\n",
        "            errors.append('All displacement values are missing')\n",
        "        elif (df['Crossheadmm'] < 0).any():\n",
        "            errors.append('Negative displacement values detected')\n",
        "\n",
        "    load_col = 'LoadN' if 'LoadN' in df.columns else 'LoadkN'\n",
        "    if load_col in df.columns:\n",
        "        if df[load_col].isna().all():\n",
        "            errors.append('All load values are missing')\n",
        "\n",
        "    if len(df) < 10:\n",
        "        errors.append(f'Insufficient data points: {len(df)} < 10')\n",
        "\n",
        "    return errors\n",
        "\n",
        "\n",
        "def normalize_load_column(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Ensure DataFrame has LoadN column in Newtons.\"\"\"\n",
        "    df = df.copy()\n",
        "    if 'LoadN' not in df.columns and 'LoadkN' in df.columns:\n",
        "        df['LoadN'] = df['LoadkN'] * 1000\n",
        "    return df\n",
        "\n",
        "\n",
        "def safe_trapezoid(y: np.ndarray, x: np.ndarray) -> float:\n",
        "    \"\"\"Compute area under curve using trapezoidal rule.\"\"\"\n",
        "    try:\n",
        "        return float(np.trapezoid(y, x))  # NumPy >= 2.0\n",
        "    except AttributeError:\n",
        "        return float(np.trapz(y, x))       # NumPy < 2.0\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STIFFNESS ANALYSIS (from analysis_pipeline.py)\n",
        "# ============================================================================\n",
        "\n",
        "def find_best_stiffness(\n",
        "    x: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    window_size: int,\n",
        "    r2_threshold: float\n",
        ") -> Tuple[float, float, float, int, int]:\n",
        "    \"\"\"\n",
        "    Scan the curve to find the stiffest linear region using a sliding window.\n",
        "    Returns (slope, intercept, r_squared, start_idx, end_idx).\n",
        "    \"\"\"\n",
        "    best_r2 = -np.inf\n",
        "    best_slope = 0.0\n",
        "    best_params = (np.nan, np.nan, np.nan, 0, 0)\n",
        "\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    y = np.asarray(y, dtype=np.float64)\n",
        "\n",
        "    n_points = len(x)\n",
        "    if n_points < window_size:\n",
        "        return best_params\n",
        "\n",
        "    for i in range(n_points - window_size):\n",
        "        x_win = x[i : i + window_size].reshape(-1, 1)\n",
        "        y_win = y[i : i + window_size]\n",
        "\n",
        "        model = LinearRegression().fit(x_win, y_win)\n",
        "        y_pred = model.predict(x_win)\n",
        "\n",
        "        r2 = r2_score(y_win, y_pred)\n",
        "        slope = float(model.coef_[0])\n",
        "        intercept = float(model.intercept_)\n",
        "\n",
        "        if r2 >= r2_threshold:\n",
        "            if slope > best_slope:\n",
        "                best_slope = slope\n",
        "                best_params = (slope, intercept, r2, i, i + window_size)\n",
        "\n",
        "        if r2 > best_r2 and best_slope == 0:\n",
        "            best_r2 = r2\n",
        "            best_params = (slope, intercept, r2, i, i + window_size)\n",
        "\n",
        "    return best_params\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# BATCH PROCESSING (from analysis_pipeline.py)\n",
        "# ============================================================================\n",
        "\n",
        "def process_all_files(\n",
        "    data_dir: Path,\n",
        "    tfl_ids: List[str],\n",
        "    msc_ids: List[str],\n",
        "    r2_threshold: float,\n",
        "    window_fraction: float,\n",
        "    min_window: int,\n",
        "    excluded_samples: Optional[List[str]] = None\n",
        ") -> Optional[pd.DataFrame]:\n",
        "    \"\"\"Process all CSV files in the data folder and return analysis results.\"\"\"\n",
        "    if not data_dir.exists():\n",
        "        print(f'ERROR: Folder not found: {data_dir}')\n",
        "        return None\n",
        "\n",
        "    excluded = set(excluded_samples) if excluded_samples else set()\n",
        "\n",
        "    files = sorted([f for f in data_dir.iterdir() if f.suffix.lower() == '.csv'])\n",
        "    data_records: List[Dict] = []\n",
        "\n",
        "    print(f'Found {len(files)} files. Excluded samples: {sorted(excluded) if excluded else \"none\"}')\n",
        "\n",
        "    for file_path in files:\n",
        "        filename = file_path.name\n",
        "        try:\n",
        "            s_id, cond, sub = classify_sample(filename, tfl_ids, msc_ids)\n",
        "\n",
        "            # Skip excluded samples\n",
        "            if s_id in excluded:\n",
        "                print(f'  SKIP {filename}: sample {s_id} is excluded.')\n",
        "                continue\n",
        "\n",
        "            if cond == 'Unknown':\n",
        "                print(f'  SKIP {filename}: Could not determine NO/OPER.')\n",
        "                continue\n",
        "\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            validation_errors = validate_raw_data(df)\n",
        "            if validation_errors:\n",
        "                print(f'  SKIP {filename}: {\"; \".join(validation_errors)}')\n",
        "                continue\n",
        "\n",
        "            df = normalize_load_column(df)\n",
        "            y_col = 'LoadN'\n",
        "\n",
        "            # Truncate at max load (failure point)\n",
        "            max_idx = df[y_col].idxmax()\n",
        "            df_trunc = df.iloc[: max_idx + 1].copy()\n",
        "            x = df_trunc['Crossheadmm'].values\n",
        "            y = df_trunc[y_col].values\n",
        "\n",
        "            # Calculate energy (area under curve)\n",
        "            energy_mJ = safe_trapezoid(y, x)\n",
        "\n",
        "            # Find stiffness using sliding window\n",
        "            window_span = max(min_window, int(len(x) * window_fraction))\n",
        "            slope, intercept, r2, idx_start, idx_end = find_best_stiffness(\n",
        "                x, y, window_span, r2_threshold\n",
        "            )\n",
        "\n",
        "            data_records.append({\n",
        "                'Filename': filename,\n",
        "                'SampleID': s_id,\n",
        "                'Subgroup': sub,\n",
        "                'MaxLoad_N': float(df[y_col].max()),\n",
        "                'Stiffness_N_mm': slope,\n",
        "                'Energy_mJ': energy_mJ,\n",
        "                'R2_Score': r2,\n",
        "                'Linear_Start_Idx': idx_start,\n",
        "                'Linear_End_Idx': idx_end\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'  ERROR {filename}: {e}')\n",
        "\n",
        "    return pd.DataFrame(data_records)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STATISTICS (from analysis_pipeline.py)\n",
        "# ============================================================================\n",
        "\n",
        "def generate_statistics(metadata: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Generate group statistics from the analysis results.\"\"\"\n",
        "    def list_ids(series: pd.Series) -> str:\n",
        "        return ', '.join(sorted(series.unique()))\n",
        "\n",
        "    stats = metadata.groupby('Subgroup').agg(\n",
        "        MaxLoad_Mean=('MaxLoad_N', 'mean'),\n",
        "        MaxLoad_Std=('MaxLoad_N', 'std'),\n",
        "        Stiffness_Mean=('Stiffness_N_mm', 'mean'),\n",
        "        Stiffness_Std=('Stiffness_N_mm', 'std'),\n",
        "        Energy_Mean=('Energy_mJ', 'mean'),\n",
        "        Energy_Std=('Energy_mJ', 'std'),\n",
        "        Count=('SampleID', 'count'),\n",
        "        Sample_List=('SampleID', list_ids)\n",
        "    ).round(2)\n",
        "\n",
        "    return stats\n",
        "\n",
        "\n",
        "print('\\nAll functions defined. Ready to run the pipeline.')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "setup_cell"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Understanding the Classification\n",
        "\n",
        "The `classify_sample()` function determines which group a sample belongs to based on its filename.\n",
        "\n",
        "**Logic:**\n",
        "- Filenames contain: `SSP_YYYY-MM-DD_SubjectID_Condition.csv`\n",
        "- Condition is either `NO` (non-operated control) or `OPER` (operated)\n",
        "- Non-operated samples are always in the `NON` (control) group\n",
        "- Operated samples are assigned to `TFL` or `MSC` based on the hardcoded group IDs"
      ],
      "id": "0d128ac1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demonstrate the classification function\n",
        "test_files = [\n",
        "    'SSP_2025-03-17_D1_NO.csv',\n",
        "    'SSP_2025-03-17_D1_OPER.csv',\n",
        "    'SSP_2025-03-20_D9_OPER.csv'\n",
        "]\n",
        "\n",
        "print('Classification examples:')\n",
        "print('-' * 60)\n",
        "for f in test_files:\n",
        "    sample_id, condition, subgroup = classify_sample(f, TFL_IDS, MSC_IDS)\n",
        "    print(f'{f}')\n",
        "    print(f'  -> Sample: {sample_id}, Condition: {condition}, Group: {subgroup}')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "80c202f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Run the Analysis Pipeline\n",
        "\n",
        "The analysis pipeline processes all CSV files and calculates:\n",
        "\n",
        "1. **Max Load (N)** - Ultimate failure load\n",
        "2. **Stiffness (N/mm)** - Slope of the stiffest linear region (using sliding window)\n",
        "3. **Energy (mJ)** - Area under the load-displacement curve (work to failure)\n",
        "\n",
        "**Stiffness Calculation:**\n",
        "We use a sliding window approach to find the region with:\n",
        "- Highest slope (stiffness)\n",
        "- Good linearity (R² > 0.99)"
      ],
      "id": "656deda7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run the analysis pipeline (uses ACTIVE lists, which respect EXCLUDED_SAMPLES)\n",
        "metadata = process_all_files(\n",
        "    data_dir=DATA_FOLDER,\n",
        "    tfl_ids=ACTIVE_TFL,\n",
        "    msc_ids=ACTIVE_MSC,\n",
        "    r2_threshold=STIFFNESS_R2_THRESHOLD,\n",
        "    window_fraction=STIFFNESS_WINDOW_FRACTION,\n",
        "    min_window=STIFFNESS_MIN_WINDOW,\n",
        "    excluded_samples=EXCLUDED_SAMPLES\n",
        ")\n",
        "\n",
        "if metadata is not None:\n",
        "    print(f'\\nProcessed {len(metadata)} samples successfully.')\n",
        "    display(metadata.head(10))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f1b792df"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Group Statistics\n",
        "\n",
        "Generate summary statistics for each treatment group:\n",
        "- **NON** - Non-operated control (intact rotator cuff)\n",
        "- **TFL** - Tensor fascia lata allograft\n",
        "- **MSC** - TFL + Mesenchymal stem cells"
      ],
      "id": "cd8e1169"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate statistics\n",
        "stats = generate_statistics(metadata)\n",
        "display(stats)\n",
        "\n",
        "# Save results to CSV\n",
        "detail_path = RESULTS_FOLDER / 'Experiment_Master_Log_Detailed.csv'\n",
        "metadata.to_csv(detail_path, index=False)\n",
        "print(f'\\nSaved detailed results to: {detail_path}')\n",
        "\n",
        "stats_path = RESULTS_FOLDER / 'Group_Statistics_Detailed.csv'\n",
        "stats.to_csv(stats_path)\n",
        "print(f'Saved group statistics to: {stats_path}')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d5e8c5b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Visualization - Group Comparison Bar Charts\n",
        "\n",
        "Compare the three groups across all metrics with error bars showing standard deviation."
      ],
      "id": "6bf2eb76"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create comparison bar charts\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "groups = ['NON', 'TFL', 'MSC']\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "metrics = ['MaxLoad_N', 'Stiffness_N_mm', 'Energy_mJ']\n",
        "titles = ['Max Load (N)', 'Stiffness (N/mm)', 'Energy (mJ)']\n",
        "\n",
        "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
        "    means = [metadata[metadata['Subgroup'] == g][metric].mean() for g in groups]\n",
        "    stds = [metadata[metadata['Subgroup'] == g][metric].std() for g in groups]\n",
        "    counts = [len(metadata[metadata['Subgroup'] == g]) for g in groups]\n",
        "    \n",
        "    bars = axes[i].bar(groups, means, color=colors, alpha=0.8, edgecolor='black')\n",
        "    axes[i].errorbar(groups, means, yerr=stds, fmt='none', color='black', capsize=5)\n",
        "    \n",
        "    # Add sample counts\n",
        "    for j, bar in enumerate(bars):\n",
        "        std_val = stds[j] if not np.isnan(stds[j]) else 0\n",
        "        axes[i].text(\n",
        "            bar.get_x() + bar.get_width() / 2,\n",
        "            bar.get_height() + std_val + 5,\n",
        "            f'n={counts[j]}',\n",
        "            ha='center', va='bottom', fontsize=10\n",
        "        )\n",
        "    \n",
        "    axes[i].set_title(title, fontsize=14, fontweight='bold')\n",
        "    axes[i].set_ylabel(title)\n",
        "    axes[i].set_xlabel('Treatment Group')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "plot_path = RESULTS_FOLDER / 'Combined_Group_Plots.png'\n",
        "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "print(f'Saved plot to: {plot_path}')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a1b2c3d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Individual Load-Displacement Curves\n",
        "\n",
        "Plot the raw load-displacement curves for each group to visualize the mechanical behavior."
      ],
      "id": "35f6ff24"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_group_curves(group_name, group_df, ax, colormap_name='viridis'):\n",
        "    \"\"\"Plot load-displacement curves for a group.\"\"\"\n",
        "    cmap = plt.get_cmap(colormap_name)\n",
        "    n_samples = len(group_df)\n",
        "    \n",
        "    for idx, (_, row) in enumerate(group_df.iterrows()):\n",
        "        filename = row['Filename']\n",
        "        filepath = DATA_FOLDER / filename\n",
        "        \n",
        "        if not filepath.exists():\n",
        "            continue\n",
        "            \n",
        "        df = pd.read_csv(filepath)\n",
        "        if 'LoadN' not in df.columns and 'LoadkN' in df.columns:\n",
        "            df['LoadN'] = df['LoadkN'] * 1000\n",
        "        \n",
        "        # Truncate at max load\n",
        "        max_idx = df['LoadN'].idxmax()\n",
        "        df_trunc = df.iloc[:max_idx + 1]\n",
        "        \n",
        "        color = cmap(idx / max(n_samples - 1, 1))\n",
        "        ax.plot(\n",
        "            df_trunc['Crossheadmm'], \n",
        "            df_trunc['LoadN'],\n",
        "            color=color,\n",
        "            alpha=0.7,\n",
        "            linewidth=1.5,\n",
        "            label=row['SampleID']\n",
        "        )\n",
        "    \n",
        "    ax.set_title(f'{group_name} Group (n={n_samples})', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Displacement (mm)')\n",
        "    ax.set_ylabel('Load (N)')\n",
        "    ax.legend(loc='upper left', fontsize=8, ncol=2)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "# Create subplots for each group\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "group_configs = [\n",
        "    ('NON', 'Greens'),\n",
        "    ('TFL', 'Blues'),\n",
        "    ('MSC', 'Reds')\n",
        "]\n",
        "\n",
        "for ax, (group_name, colormap) in zip(axes, group_configs):\n",
        "    group_df = metadata[metadata['Subgroup'] == group_name]\n",
        "    plot_group_curves(group_name, group_df, ax, colormap)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save individual group plots\n",
        "for group_name, colormap in group_configs:\n",
        "    fig_single, ax_single = plt.subplots(figsize=(10, 6))\n",
        "    group_df = metadata[metadata['Subgroup'] == group_name]\n",
        "    plot_group_curves(group_name, group_df, ax_single, colormap)\n",
        "    plot_path = RESULTS_FOLDER / f'Plot_{group_name}.png'\n",
        "    fig_single.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close(fig_single)\n",
        "    print(f'Saved: {plot_path}')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e5f6g7h8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Interactive Plots (Plotly)\n",
        "\n",
        "If Plotly is available, create interactive plots for detailed exploration."
      ],
      "id": "07839e80"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if PLOTLY_AVAILABLE:\n",
        "    # Create interactive comparison chart\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=3,\n",
        "        subplot_titles=['Max Load (N)', 'Stiffness (N/mm)', 'Energy (mJ)']\n",
        "    )\n",
        "    \n",
        "    colors_plotly = {'NON': '#2ecc71', 'TFL': '#3498db', 'MSC': '#e74c3c'}\n",
        "    \n",
        "    for i, metric in enumerate(['MaxLoad_N', 'Stiffness_N_mm', 'Energy_mJ']):\n",
        "        for group in ['NON', 'TFL', 'MSC']:\n",
        "            group_data = metadata[metadata['Subgroup'] == group][metric]\n",
        "            fig.add_trace(\n",
        "                go.Box(\n",
        "                    y=group_data,\n",
        "                    name=group,\n",
        "                    marker_color=colors_plotly[group],\n",
        "                    showlegend=(i == 0)\n",
        "                ),\n",
        "                row=1, col=i+1\n",
        "            )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='Biomechanical Properties by Treatment Group',\n",
        "        height=500,\n",
        "        showlegend=True\n",
        "    )\n",
        "    fig.show()\n",
        "else:\n",
        "    print('Plotly not available. Skipping interactive plots.')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "i9j0k1l2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: Stiffness Visualization (All Subjects)\n",
        "\n",
        "Show the linear region used for stiffness calculation on **every sample**, organized by group."
      ],
      "id": "001d8b3f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_stiffness_region(sample_row):\n",
        "    \"\"\"Plot a sample's curve with the linear region highlighted.\"\"\"\n",
        "    filename = sample_row['Filename']\n",
        "    filepath = DATA_FOLDER / filename\n",
        "    \n",
        "    df = pd.read_csv(filepath)\n",
        "    if 'LoadN' not in df.columns and 'LoadkN' in df.columns:\n",
        "        df['LoadN'] = df['LoadkN'] * 1000\n",
        "    \n",
        "    # Truncate at max load\n",
        "    max_idx = df['LoadN'].idxmax()\n",
        "    df_trunc = df.iloc[:max_idx + 1]\n",
        "    \n",
        "    x = df_trunc['Crossheadmm'].values\n",
        "    y = df_trunc['LoadN'].values\n",
        "    \n",
        "    # Get linear region indices\n",
        "    start_idx = int(sample_row['Linear_Start_Idx'])\n",
        "    end_idx = int(sample_row['Linear_End_Idx'])\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    # Plot full curve\n",
        "    ax.plot(x, y, 'b-', linewidth=2, label='Load-Displacement Curve')\n",
        "    \n",
        "    # Highlight linear region\n",
        "    ax.plot(x[start_idx:end_idx], y[start_idx:end_idx], 'r-', \n",
        "            linewidth=3, label=f'Linear Region (R\\u00b2={sample_row[\"R2_Score\"]:.4f})')\n",
        "    \n",
        "    # Add linear fit line\n",
        "    slope = sample_row['Stiffness_N_mm']\n",
        "    x_fit = x[start_idx:end_idx]\n",
        "    y_fit_start = y[start_idx]\n",
        "    y_fit = y_fit_start + slope * (x_fit - x_fit[0])\n",
        "    ax.plot(x_fit, y_fit, 'g--', linewidth=2, \n",
        "            label=f'Stiffness = {slope:.1f} N/mm')\n",
        "    \n",
        "    ax.set_xlabel('Displacement (mm)', fontsize=12)\n",
        "    ax.set_ylabel('Load (N)', fontsize=12)\n",
        "    ax.set_title(f'{filename}\\nMax Load: {sample_row[\"MaxLoad_N\"]:.1f} N, '\n",
        "                 f'Energy: {sample_row[\"Energy_mJ\"]:.1f} mJ', fontsize=12)\n",
        "    ax.legend(loc='upper left')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Plot ALL subjects organized by group\n",
        "for group in ['NON', 'TFL', 'MSC']:\n",
        "    group_df = metadata[metadata['Subgroup'] == group]\n",
        "    n_samples = len(group_df)\n",
        "    \n",
        "    if n_samples == 0:\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f'{group} GROUP ({n_samples} samples)')\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    for idx, (_, sample) in enumerate(group_df.iterrows()):\n",
        "        print(f\"\\n[{idx+1}/{n_samples}] {sample['SampleID']}:\")\n",
        "        fig = plot_stiffness_region(sample)\n",
        "        plt.show()\n",
        "        plt.close(fig)  # Close to free memory"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "m3n4o5p6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates the biomechanical analysis pipeline for the SSP study.\n",
        "\n",
        "**Key Findings:**\n",
        "- Non-operated (NON) samples show the highest mechanical properties (intact tissue)\n",
        "- MSC group shows improved properties compared to TFL-only group\n",
        "- Both operated groups show significantly reduced properties vs. intact controls\n",
        "\n",
        "**Files Generated:**\n",
        "- `Results/Experiment_Master_Log_Detailed.csv` - All sample data\n",
        "- `Results/Group_Statistics_Detailed.csv` - Summary statistics\n",
        "- `Results/Combined_Group_Plots.png` - Comparison bar charts\n",
        "- `Results/Plot_NON.png`, `Plot_TFL.png`, `Plot_MSC.png` - Individual group curves"
      ],
      "id": "summary_cell"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}